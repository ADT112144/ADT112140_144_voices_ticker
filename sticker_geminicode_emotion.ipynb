{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPVOxQ1zIez7",
        "outputId": "7f24e6fc-e073-4c27-8275-0459d7ebeb95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â³ æ­£åœ¨å®‰è£æœ€æ–°ç‰ˆ Google GenAI SDK èˆ‡å…¶ä»–å·¥å…·ï¼Œè«‹ç¨å€™ (ç´„ 1-2 åˆ†é˜)...\n",
            "âœ… å·¥å…·å®‰è£å®Œæˆï¼é–‹å§‹åŒ¯å…¥ä¸¦å•Ÿå‹•...\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# 1. å®‰è£å€ï¼šå®‰è£æœ€æ–°çš„ Google GenAI SDK å’Œå…¶ä»–å·¥å…·\n",
        "# =============================================================================\n",
        "print(\"â³ æ­£åœ¨å®‰è£æœ€æ–°ç‰ˆ Google GenAI SDK èˆ‡å…¶ä»–å·¥å…·ï¼Œè«‹ç¨å€™ (ç´„ 1-2 åˆ†é˜)...\")\n",
        "from IPython.utils import io\n",
        "with io.capture_output() as captured:\n",
        "    # æ³¨æ„ï¼šé€™è£¡æˆ‘å€‘å®‰è£ 'google-genai' é€™æ˜¯æœ€æ–°çš„å®˜æ–¹å¥—ä»¶\n",
        "    !pip install -U -q google-genai openai-whisper gradio transformers torch accelerate requests\n",
        "\n",
        "print(\"âœ… å·¥å…·å®‰è£å®Œæˆï¼é–‹å§‹åŒ¯å…¥ä¸¦å•Ÿå‹•...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_oDmrIHoJisK"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 2. åŒ¯å…¥å€ï¼šä½¿ç”¨æœ€æ–°çš„å®˜æ–¹èªæ³•\n",
        "# =============================================================================\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "from urllib.parse import quote\n",
        "import gradio as gr\n",
        "import whisper\n",
        "from transformers import pipeline\n",
        "\n",
        "# â— é€™è£¡å°±æ˜¯ä½ ç™¼ç¾çš„æœ€æ–°å®˜æ–¹èªæ³•ï¼\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoUsT_W8MXWz",
        "outputId": "bd17c07e-0cce-4157-919e-f5aa30404bc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://cli.github.com/packages stable InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-noto-cjk is already the newest version (1:20220127+repack1-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n",
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc: Noto Sans CJK JP:style=Regular\n",
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc: Noto Sans CJK HK:style=Regular\n",
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc: Noto Sans CJK KR:style=Regular\n",
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc: Noto Sans CJK SC:style=Regular\n",
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc: Noto Sans CJK TC:style=Regular\n",
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc: Noto Sans Mono CJK TC:style=Bold\n",
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc: Noto Sans Mono CJK SC:style=Bold\n",
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc: Noto Sans Mono CJK KR:style=Bold\n",
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc: Noto Sans Mono CJK HK:style=Bold\n",
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc: Noto Sans Mono CJK JP:style=Bold\n"
          ]
        }
      ],
      "source": [
        "!apt-get update -y\n",
        "!apt-get install -y fonts-noto-cjk\n",
        "!fc-list | grep -i \"NotoSansCJK\" | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwxFIeVaIqxc",
        "outputId": "05762f3f-0699-4af0-aab0-84eb22203465"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â³ æ­£åœ¨å«é†’ Whisper è½å¯«æ©Ÿå™¨äºº...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… æ‰€æœ‰æ©Ÿå™¨äººéƒ½æº–å‚™å¥½äº†ï¼\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# 3. æ¨¡å‹æº–å‚™å€\n",
        "# =============================================================================\n",
        "print(\"â³ æ­£åœ¨å«é†’ Whisper è½å¯«æ©Ÿå™¨äºº...\")\n",
        "whisper_model = whisper.load_model(\"medium\")\n",
        "\n",
        "emotion_classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
        "    return_all_scores=True  # âœ… å›å‚³å¤šç¶­åº¦åˆ†æ•¸\n",
        ")\n",
        "\n",
        "print(\"âœ… æ‰€æœ‰æ©Ÿå™¨äººéƒ½æº–å‚™å¥½äº†ï¼\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uRXL_pb5MdwE"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import re\n",
        "\n",
        "FONT_PATH_REG = \"/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc\"\n",
        "FONT_PATH_BOLD = \"/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc\"\n",
        "\n",
        "def wrap_by_pixel(draw, text, font, max_width):\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    if not text:\n",
        "        return []\n",
        "    lines, buf = [], \"\"\n",
        "    for ch in text:\n",
        "        test = buf + ch\n",
        "        w = draw.textbbox((0, 0), test, font=font)[2]\n",
        "        if w <= max_width:\n",
        "            buf = test\n",
        "        else:\n",
        "            if buf:\n",
        "                lines.append(buf)\n",
        "            buf = ch\n",
        "    if buf:\n",
        "        lines.append(buf)\n",
        "    return lines\n",
        "\n",
        "def build_basic_prompt(transcribed_text, detected_emotion):\n",
        "    \"\"\"\n",
        "    ä¸ä¾è³´ Gemini çš„åŸºç¤æç¤ºè©ï¼ˆç©©å®šã€ä¸€å®šèƒ½ç”¨ï¼‰\n",
        "    \"\"\"\n",
        "    text = transcribed_text.strip()\n",
        "    emo = detected_emotion.lower()\n",
        "\n",
        "    return (\n",
        "        \"Cute 3D Pixar style sticker, chibi character, \"\n",
        "        f\"clear facial expression showing {emo} emotion, \"\n",
        "        \"simple and clean composition, \"\n",
        "        \"white background, high quality, vector style, die-cut border, \"\n",
        "        f\"the sticker clearly shows the text: '{text}'\"\n",
        "    )\n",
        "\n",
        "def add_speech_text_to_sticker_colab(image_path, speech_text, out_path=None):\n",
        "    from PIL import Image, ImageDraw, ImageFont\n",
        "    import re\n",
        "    import os\n",
        "\n",
        "    img = Image.open(image_path).convert(\"RGBA\")\n",
        "    W, H = img.size\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    text = (speech_text or \"\").strip()\n",
        "    if not text:\n",
        "        return image_path\n",
        "\n",
        "    # âœ… å­—æ›´å¤§ï¼šåŸæœ¬ max(40, W//14) å¤ªå°\n",
        "    font_size = max(84, W // 8)   # ä½ ä¹Ÿå¯ä»¥æ”¹æˆ max(64, W//9) æ¯”è¼ƒä¿å®ˆ\n",
        "\n",
        "    def _wrap_lines(font):\n",
        "        max_text_width = int(W * 0.86)  # æ²’åº•æ¿å¯ä»¥æ”¾å¯¬ä¸€é»\n",
        "        # ç”¨åƒç´ å¯¬åº¦æ›è¡Œï¼ˆé¿å…ä¸­æ–‡å¯¬åº¦ä¸ä¸€è‡´ï¼‰\n",
        "        t = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "        if not t:\n",
        "            return []\n",
        "        lines, buf = [], \"\"\n",
        "        for ch in t:\n",
        "            test = buf + ch\n",
        "            w = draw.textbbox((0, 0), test, font=font)[2]\n",
        "            if w <= max_text_width:\n",
        "                buf = test\n",
        "            else:\n",
        "                if buf:\n",
        "                    lines.append(buf)\n",
        "                buf = ch\n",
        "        if buf:\n",
        "            lines.append(buf)\n",
        "        return lines[:2]  # æœ€å¤šå…©è¡Œ\n",
        "\n",
        "    # âœ… ä½¿ç”¨ç²—é«”ä¸­æ–‡å­—å‹ï¼ˆä½ å‰é¢å·²å®šç¾© FONT_PATH_BOLDï¼‰\n",
        "    # è‹¥ä½ è®Šæ•¸åä¸åŒï¼Œæ”¹æˆä½ çš„å­—å‹è·¯å¾‘å³å¯\n",
        "    font = ImageFont.truetype(FONT_PATH_BOLD, font_size)\n",
        "\n",
        "    # è‹¥å…©è¡Œé‚„æ˜¯å¤ªé•·ï¼Œæœ€å¤šè‡ªå‹•ç¸®å° 2 æ¬¡\n",
        "    lines = _wrap_lines(font)\n",
        "    for _ in range(2):\n",
        "        if not lines:\n",
        "            return image_path\n",
        "        too_wide = False\n",
        "        for line in lines:\n",
        "            w = draw.textbbox((0, 0), line, font=font)[2]\n",
        "            if w > int(W * 0.88):\n",
        "                too_wide = True\n",
        "                break\n",
        "        if too_wide:\n",
        "            font_size = int(font_size * 0.85)\n",
        "            font = ImageFont.truetype(FONT_PATH_BOLD, font_size)\n",
        "            lines = _wrap_lines(font)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    if not lines:\n",
        "        return image_path\n",
        "\n",
        "    # æ–‡å­—é«˜åº¦\n",
        "    line_h = draw.textbbox((0, 0), \"æ¸¬\", font=font)[3]\n",
        "    gap = int(line_h * 0.18)\n",
        "    pad_y = int(H * 0.04)\n",
        "\n",
        "    # âœ… æ”¾åœ¨åº•éƒ¨ï¼Œä½†ä¸ç•«é»‘åº•\n",
        "    total_h = line_h * len(lines) + gap * (len(lines) - 1)\n",
        "    y0 = H - total_h - pad_y\n",
        "\n",
        "    # âœ… æ²’åº•æ¿æ™‚æé‚Šè¦æ›´ç²—æ‰æ¸…æ¥š\n",
        "    stroke = max(8, W // 90)\n",
        "\n",
        "    y = y0\n",
        "    for line in lines:\n",
        "        w = draw.textbbox((0, 0), line, font=font)[2]\n",
        "        x = (W - w) // 2\n",
        "        draw.text(\n",
        "            (x, y),\n",
        "            line,\n",
        "            font=font,\n",
        "            fill=(255, 255, 255, 255),      # ç™½å­—\n",
        "            stroke_width=stroke,\n",
        "            stroke_fill=(0, 0, 0, 255),      # é»‘æé‚Šï¼ˆæ›´å¯¦ï¼‰\n",
        "        )\n",
        "        y += line_h + gap\n",
        "\n",
        "    # âœ… å¼·åˆ¶è¼¸å‡º PNGï¼ˆé¿å… RGBA->JPEG å‡ºéŒ¯ï¼‰\n",
        "    if out_path is None:\n",
        "        base, _ = os.path.splitext(image_path)\n",
        "        out_path = base + \"_caption.png\"\n",
        "\n",
        "    root, ext = os.path.splitext(out_path)\n",
        "    if ext.lower() in [\".jpg\", \".jpeg\"]:\n",
        "        out_path = root + \".png\"\n",
        "\n",
        "    img.save(out_path, format=\"PNG\")\n",
        "    return out_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Jwa3g5QBIsmm"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 4. æ ¸å¿ƒåŠŸèƒ½å€ï¼šå·¥å» é‹ä½œé‚è¼¯\n",
        "# =============================================================================\n",
        "# ===== å¤šç¶­åº¦æƒ…ç·’è³‡æ–™åº«ï¼ˆå¾ã€ŒèªéŸ³è½‰è²¼åœ–_åˆæ­¥ç‰ˆæœ¬.ipynbã€ä¿ç•™æ¦‚å¿µï¼‰=====\n",
        "EMOTION_DATABASE = {\n",
        "    \"anger\": {\n",
        "        \"zh\": \"æ†¤æ€’\",\n",
        "        \"description\": \"å……æ»¿æ€’ç«ã€ä¸æ»¿å’Œæ¿€å‹•\",\n",
        "        \"visual\": \"çœ‰é ­ç·Šçšºã€å’¬ç‰™åˆ‡é½’ã€è‡‰è‰²æ¼²ç´…\",\n",
        "        \"effects\": \"ç«ç„°ã€é–ƒé›»ã€çˆ†ç‚¸ç‰¹æ•ˆ\",\n",
        "        \"colors\": [\"æ·±ç´…è‰²\", \"æ©™ç´…è‰²\", \"æš—ç°è‰²\"],\n",
        "        \"mood\": \"å¼·çƒˆã€æ¿€çƒˆã€æš´èº\",\n",
        "        \"intensity_high\": \"æš´æ€’ã€æ†¤æ…¨ã€ç«å†’ä¸‰ä¸ˆ\",\n",
        "        \"intensity_mid\": \"ç”Ÿæ°£ã€ä¸æ‚…ã€ç…©èº\",\n",
        "        \"intensity_low\": \"å¾®æ…ã€ä¸å¿«ã€çšºçœ‰\"\n",
        "    },\n",
        "    \"disgust\": {\n",
        "        \"zh\": \"å­æƒ¡\",\n",
        "        \"description\": \"åæ„Ÿã€æ’æ–¥å’Œä¸é©\",\n",
        "        \"visual\": \"çšºé¼»å­ã€å˜´è§’ä¸‹å‚ã€å¾Œé€€å§¿æ…‹\",\n",
        "        \"effects\": \"è‡­å‘³æ³¢ç´‹ã€ç¶ è‰²ç…™éœ§ã€è­¦å‘Šç¬¦è™Ÿ\",\n",
        "        \"colors\": [\"æš—ç¶ è‰²\", \"ç°ç¶ è‰²\", \"åœŸé»ƒè‰²\"],\n",
        "        \"mood\": \"ä¸é©ã€æ’æ–¥ã€å«Œæƒ¡\",\n",
        "        \"intensity_high\": \"ä½œå˜”ã€æ¥µåº¦å­æƒ¡ã€å™å¿ƒåˆ°çˆ†\",\n",
        "        \"intensity_mid\": \"å­æƒ¡ã€åæ„Ÿã€å«Œæ£„\",\n",
        "        \"intensity_low\": \"ä¸å–œæ­¡ã€çšºçœ‰ã€ç•¥å«Œ\"\n",
        "    },\n",
        "    \"fear\": {\n",
        "        \"zh\": \"ææ‡¼\",\n",
        "        \"description\": \"ç·Šå¼µã€å®³æ€•å’Œä¸å®‰\",\n",
        "        \"visual\": \"ç³å­”æ”¾å¤§ã€å†·æ±—ã€ç¸®è‚©ç™¼æŠ–\",\n",
        "        \"effects\": \"é™°å½±ã€é¡«æŠ–ç·šæ¢ã€é©šåš‡ç¬¦è™Ÿ\",\n",
        "        \"colors\": [\"æ·±ç´«è‰²\", \"æ·±è—è‰²\", \"ç°é»‘è‰²\"],\n",
        "        \"mood\": \"ç·Šç¹ƒã€é©šæ…Œã€ä¸å®‰\",\n",
        "        \"intensity_high\": \"é©šæã€åš‡å£ã€é­‚é£›é­„æ•£\",\n",
        "        \"intensity_mid\": \"å®³æ€•ã€ç·Šå¼µã€å¿ƒæ…Œ\",\n",
        "        \"intensity_low\": \"ä¸å®‰ã€æ“”å¿ƒã€æˆ’å‚™\"\n",
        "    },\n",
        "    \"joy\": {\n",
        "        \"zh\": \"å–œæ‚…\",\n",
        "        \"description\": \"å¿«æ¨‚ã€èˆˆå¥®å’Œæ»¿è¶³\",\n",
        "        \"visual\": \"ç‡¦çˆ›ç¬‘å®¹ã€çœ¼ç›å½å½ã€è·³èºå§¿å‹¢\",\n",
        "        \"effects\": \"æ˜Ÿæ˜Ÿã€å½©å¸¶ã€é–ƒäº®å…‰é»\",\n",
        "        \"colors\": [\"æ˜é»ƒè‰²\", \"ç²‰ç´…è‰²\", \"å¤©è—è‰²\"],\n",
        "        \"mood\": \"æ­¡æ¨‚ã€æ„‰æ‚…ã€é›€èº\",\n",
        "        \"intensity_high\": \"ç‹‚å–œã€æ¬£å–œè‹¥ç‹‚ã€æ¨‚é–‹æ‡·\",\n",
        "        \"intensity_mid\": \"é–‹å¿ƒã€å¿«æ¨‚ã€æ»¿è¶³\",\n",
        "        \"intensity_low\": \"å¾®ç¬‘ã€æ„‰å¿«ã€å¿ƒæƒ…å¥½\"\n",
        "    },\n",
        "    \"sadness\": {\n",
        "        \"zh\": \"æ‚²å‚·\",\n",
        "        \"description\": \"é›£éã€å¤±è½å’Œä½è½\",\n",
        "        \"visual\": \"çœ¼è§’å«æ·šã€å˜´è§’ä¸‹å‚ã€å‚é ­å–ªæ°£\",\n",
        "        \"effects\": \"é›¨æ»´ã€æ·šæ°´ã€å°æ°´çªª\",\n",
        "        \"colors\": [\"æ·ºè—è‰²\", \"ç°è—è‰²\", \"æ·¡ç´«è‰²\"],\n",
        "        \"mood\": \"æ†‚é¬±ã€å¤±è½ã€æ„Ÿå‚·\",\n",
        "        \"intensity_high\": \"ç—›å“­ã€å¿ƒç¢ã€æ‚²ç—›æ¬²çµ•\",\n",
        "        \"intensity_mid\": \"é›£éã€æ²®å–ªã€å¤±è½\",\n",
        "        \"intensity_low\": \"æ·¡æ·¡å“€å‚·ã€æ‚¶æ‚¶çš„ã€ä½è½\"\n",
        "    },\n",
        "    \"surprise\": {\n",
        "        \"zh\": \"é©šè¨\",\n",
        "        \"description\": \"æ„å¤–ã€éœ‡é©šå’Œçªç„¶æ„Ÿ\",\n",
        "        \"visual\": \"å¼µå¤§å˜´å·´ã€çœ‰æ¯›ä¸Šæšã€çœ¼ç›çœå¤§\",\n",
        "        \"effects\": \"é©šå˜†è™Ÿã€çˆ†ç‚¸ç·šã€äº®å…‰\",\n",
        "        \"colors\": [\"äº®æ©™è‰²\", \"äº®é»ƒè‰²\", \"ç™½è‰²\"],\n",
        "        \"mood\": \"çªç™¼ã€é©šå¥‡ã€æ„å¤–\",\n",
        "        \"intensity_high\": \"éœ‡é©šã€é©šå‘†ã€ä¸å¯æ€è­°\",\n",
        "        \"intensity_mid\": \"é©šè¨ã€æ„å¤–ã€å“‡å¡\",\n",
        "        \"intensity_low\": \"å°é©šå–œã€ç•¥æ„å¤–ã€å“¦ï¼Ÿ\"\n",
        "    },\n",
        "    \"neutral\": {\n",
        "        \"zh\": \"å¹³éœ\",\n",
        "        \"description\": \"å†·éœã€å¹³å’Œå’Œä¸­æ€§\",\n",
        "        \"visual\": \"è¡¨æƒ…è‡ªç„¶ã€çœ¼ç¥å¹³å’Œã€å§¿æ…‹æ”¾é¬†\",\n",
        "        \"effects\": \"ç°¡ç´„ç·šæ¢ã€å¹¾ä½•åœ–å½¢\",\n",
        "        \"colors\": [\"æ·¡è—è‰²\", \"ç±³ç™½è‰²\", \"æ·ºç°è‰²\"],\n",
        "        \"mood\": \"æ·¡å®šã€å¹³ç©©ã€ç†æ€§\",\n",
        "        \"intensity_high\": \"éå¸¸å†·éœã€æ³°ç„¶è‡ªè‹¥ã€ç©©å¦‚æ³°å±±\",\n",
        "        \"intensity_mid\": \"å¹³éœã€æ­£å¸¸ã€æ·¡å®š\",\n",
        "        \"intensity_low\": \"ç•¥å¾®ç„¡æ„Ÿã€æ·¡æ·¡çš„ã€é‚„å¥½\"\n",
        "    }\n",
        "}\n",
        "\n",
        "EMOTION_FALLBACK = {\n",
        "    \"positive\": \"joy\",\n",
        "    \"negative\": \"sadness\",\n",
        "    \"POSITIVE\": \"joy\",\n",
        "    \"NEGATIVE\": \"sadness\",\n",
        "    \"NEUTRAL\": \"neutral\"\n",
        "}\n",
        "\n",
        "def analyze_emotions_multi(text: str, top_k: int = 3):\n",
        "    \"\"\"æŠŠ pipeline çš„ all_scores è½‰æˆæ’åºå¾Œçš„å¤šç¶­åº¦æƒ…ç·’åˆ—è¡¨\"\"\"\n",
        "    if not text or not emotion_classifier:\n",
        "        return []\n",
        "\n",
        "    results = emotion_classifier(text[:512])\n",
        "\n",
        "    # pipeline å›å‚³æ ¼å¼é€šå¸¸æ˜¯ï¼š[ [ {label, score}, ... ] ]\n",
        "    if isinstance(results, list) and len(results) > 0 and isinstance(results[0], list):\n",
        "        scores = results[0]\n",
        "    else:\n",
        "        scores = results\n",
        "\n",
        "    cleaned = []\n",
        "    for r in scores:\n",
        "        label = r.get(\"label\", \"\")\n",
        "        score = float(r.get(\"score\", 0))\n",
        "        label = EMOTION_FALLBACK.get(label, label).lower()\n",
        "        cleaned.append({\"label\": label, \"score\": score})\n",
        "\n",
        "    cleaned.sort(key=lambda x: x[\"score\"], reverse=True)\n",
        "    return cleaned[:top_k]\n",
        "\n",
        "def generate_emotion_description(emotions):\n",
        "    \"\"\"ç”¨ top1 + æ¬¡è¦æƒ…ç·’ çµ„åˆæˆã€çµ„åˆæè¿°ã€çµ¦ Gemini ç”¨\"\"\"\n",
        "    if not emotions:\n",
        "        return \"ï¼ˆæœªåµæ¸¬åˆ°æƒ…ç·’ï¼‰\"\n",
        "\n",
        "    primary = emotions[0]\n",
        "    primary_label = EMOTION_FALLBACK.get(primary[\"label\"], primary[\"label\"])\n",
        "    primary_score = primary[\"score\"]\n",
        "\n",
        "    emotion_data = EMOTION_DATABASE.get(primary_label, EMOTION_DATABASE[\"neutral\"])\n",
        "\n",
        "    # å¼·åº¦åˆ†ç´šï¼ˆä½ å¯ä»¥è‡ªå·±èª¿é–€æª»ï¼‰\n",
        "    if primary_score >= 0.60:\n",
        "        intensity = emotion_data[\"intensity_high\"]\n",
        "    elif primary_score >= 0.35:\n",
        "        intensity = emotion_data[\"intensity_mid\"]\n",
        "    else:\n",
        "        intensity = emotion_data[\"intensity_low\"]\n",
        "\n",
        "    # æ¬¡è¦æƒ…ç·’ï¼ˆç°¡å–®æŒ‘ score >= 0.20 çš„ï¼‰\n",
        "    secondary = []\n",
        "    for e in emotions[1:]:\n",
        "        if e[\"score\"] >= 0.20:\n",
        "            zh = EMOTION_DATABASE.get(e[\"label\"], EMOTION_DATABASE[\"neutral\"])[\"zh\"]\n",
        "            secondary.append(f\"{zh}({e['score']:.0%})\")\n",
        "\n",
        "    desc = f\"\"\"ã€å¤šç¶­åº¦æƒ…ç·’çµ„åˆæè¿°ã€‘\n",
        "- ä¸»è¦æƒ…ç·’ï¼š{emotion_data['zh']}ï¼ˆ{primary_score:.0%}ï¼‰â†’ {intensity}\n",
        "- æƒ…ç·’ç‰¹å¾µï¼š{emotion_data['description']}\n",
        "- è¦–è¦ºè¡¨ç¾ï¼š{emotion_data['visual']}\n",
        "- ç‰¹æ•ˆå…ƒç´ ï¼š{emotion_data['effects']}\n",
        "- å»ºè­°é…è‰²ï¼š{\", \".join(emotion_data['colors'])}\n",
        "- æ°›åœæ„Ÿå—ï¼š{emotion_data['mood']}\n",
        "\"\"\"\n",
        "    if secondary:\n",
        "        desc += f\"- æ¬¡è¦æƒ…ç·’ï¼š{', '.join(secondary)}\\n\"\n",
        "\n",
        "    return desc\n",
        "\n",
        "def generate_image_from_pollinations(prompt):\n",
        "    \"\"\"\n",
        "    è² è²¬ç”Ÿåœ–çš„åŠŸèƒ½ (Pollinations AI)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        encoded_prompt = quote(prompt)\n",
        "        url = f\"https://image.pollinations.ai/prompt/{encoded_prompt}\"\n",
        "        params = {\n",
        "            \"width\": 1024,\n",
        "            \"height\": 1024,\n",
        "            \"model\": \"flux\",\n",
        "            \"seed\": int(time.time()),\n",
        "            \"nologo\": \"true\"\n",
        "        }\n",
        "\n",
        "        print(f\"æ­£åœ¨è«‹æ±‚ç”Ÿåœ–... Prompt: {prompt[:30]}...\")\n",
        "        response = requests.get(url, params=params, timeout=60)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            filename = f\"sticker_{int(time.time())}.jpg\"\n",
        "            with open(filename, \"wb\") as f:\n",
        "                f.write(response.content)\n",
        "            return filename\n",
        "        else:\n",
        "            print(f\"ç”Ÿåœ–å¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {response.status_code}\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ç”Ÿåœ–ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_pipeline(api_key, audio_path, use_gemini):\n",
        "    \"\"\"\n",
        "    ç¸½æŒ‡æ®ï¼šéŒ„éŸ³ -> æ–‡å­— -> æƒ…ç·’ -> æç¤ºè© (Gemini å¯é¸) -> åœ–ç‰‡\n",
        "    \"\"\"\n",
        "    # --- é˜²å‘†æª¢æŸ¥ ---\n",
        "    # åªæœ‰åœ¨ã€Œä½¿ç”¨ Geminiã€æ™‚ï¼Œæ‰è¦æ±‚è¼¸å…¥ API Key\n",
        "    if use_gemini and not api_key:\n",
        "        return \"âŒ å·²é¸æ“‡ä½¿ç”¨ Geminiï¼Œè«‹è¼¸å…¥ API Key\", \"ç„¡\", \"ç„¡\", None\n",
        "\n",
        "    # ä¸è«–æ˜¯å¦ä½¿ç”¨ Geminiï¼ŒèªéŸ³éƒ½æ˜¯å¿…è¦çš„\n",
        "    if not audio_path:\n",
        "        return \"âŒ è«‹å…ˆéŒ„éŸ³\", \"ç„¡\", \"ç„¡\", None\n",
        "\n",
        "    try:\n",
        "        # ============================================================\n",
        "        # æ­¥é©Ÿ A: èªéŸ³è½‰æ–‡å­—\n",
        "        # ============================================================\n",
        "        result = whisper_model.transcribe(\n",
        "            audio_path,\n",
        "            language=\"zh\",          # æ˜ç¢ºæŒ‡å®šä¸­æ–‡\n",
        "            task=\"transcribe\",\n",
        "            fp16=False,             # â—CPU ä¸€å®šè¦ False\n",
        "            temperature=0.0,        # é™ä½éš¨æ©Ÿæ€§ï¼Œæé«˜ç©©å®šåº¦\n",
        "            beam_size=5,            # Beam search æå‡æº–ç¢ºåº¦\n",
        "            best_of=5,\n",
        "            patience=1.0,\n",
        "            condition_on_previous_text=True,\n",
        "            initial_prompt=\"ä»¥ä¸‹æ˜¯æ™®é€šè©±çš„å¥å­ã€‚\",  # ä¸­æ–‡èªå¢ƒæç¤º\n",
        "        )\n",
        "        transcribed_text = result[\"text\"]\n",
        "\n",
        "        # ============================================================\n",
        "        # æ­¥é©Ÿ B: å¤šç¶­åº¦æƒ…ç·’åˆ†æ + çµ„åˆæè¿°\n",
        "        # ============================================================\n",
        "        emotions = analyze_emotions_multi(transcribed_text, top_k=3)\n",
        "        emotion_combo_desc = generate_emotion_description(emotions)\n",
        "\n",
        "        # è®“ç³»çµ±ä»ä¿ç•™ã€Œä¸»è¦æƒ…ç·’ labelã€ï¼ˆçµ¦åŸºæœ¬ prompt ç”¨ï¼‰\n",
        "        detected_emotion = emotions[0][\"label\"] if emotions else \"neutral\"\n",
        "\n",
        "        # ============================================================\n",
        "        # æ­¥é©Ÿ C: ç”¢ç”Ÿç”Ÿåœ–æç¤ºè©ï¼ˆGemini å¯é¸ / å¯é€€å›åŸºæœ¬ç‰ˆæœ¬ï¼‰\n",
        "        # ============================================================\n",
        "        prompt_for_image = None  # âœ… çœŸçš„æ‹¿å»ç”Ÿåœ–çš„ promptï¼ˆè¦ä¹¾æ·¨ï¼‰\n",
        "        prompt_for_ui = None     # âœ… é¡¯ç¤ºçµ¦ä½¿ç”¨è€…çœ‹çš„ promptï¼ˆå¯åŠ æ¨™ç±¤ï¼‰\n",
        "        gemini_error = None      # âœ… Gemini å¤±æ•—åŸå› ï¼ˆå›å‚³çµ¦ UIï¼‰\n",
        "\n",
        "        # ----------------------------\n",
        "        # C-1. ä½¿ç”¨è€…é¸æ“‡ç”¨ Gemini â†’ å˜—è©¦å„ªåŒ–æç¤ºè©\n",
        "        # ----------------------------\n",
        "        if use_gemini:\n",
        "            try:\n",
        "                # 1. å»ºç«‹ Clientï¼ˆæ–°ç‰ˆ SDK å¯«æ³•ï¼‰\n",
        "                client = genai.Client(api_key=api_key)\n",
        "\n",
        "                # 2. è¨­å®šçµ¦ Gemini çš„ Promptï¼ˆèªªæ¸…æ¥šè¦å‰‡ï¼Œé¿å…äº‚è¼¸å‡ºï¼‰\n",
        "                prompt_text = f\"\"\"\n",
        "You are an AI sticker designer.\n",
        "\n",
        "Task:\n",
        "Based on the speech content \"{transcribed_text}\",\n",
        "generate ONE single English prompt for image generation.\n",
        "\n",
        "Emotion reference (important):\n",
        "{emotion_combo_desc}\n",
        "\n",
        "Requirements:\n",
        "1. Style: Cute 3D Pixar style sticker\n",
        "2. Content: A chibi character with facial expression matching the emotion above\n",
        "3. Keywords (must include): white background, high quality, vector style, die-cut border\n",
        "4. Output format: ONE single line English prompt only\n",
        "\"\"\"\n",
        "\n",
        "                # 3. ç™¼é€è«‹æ±‚çµ¦ Gemini\n",
        "                response = client.models.generate_content(\n",
        "                    model=\"gemini-2.5-flash\",\n",
        "                    contents=prompt_text\n",
        "                )\n",
        "\n",
        "                # 4. å–å¾— Gemini å›å‚³çš„æç¤ºè©\n",
        "                prompt_for_image = (getattr(response, \"text\", \"\") or \"\").strip()\n",
        "                prompt_for_ui = \"[GEMINI PROMPT] \" + prompt_for_image\n",
        "\n",
        "                if prompt_for_image:\n",
        "                    print(\"âœ… ä½¿ç”¨ Gemini æˆåŠŸç”¢ç”Ÿæç¤ºè©\")\n",
        "                else:\n",
        "                    print(\"âš ï¸ Gemini å›å‚³ç‚ºç©ºï¼Œå°‡æ”¹ç”¨åŸºæœ¬æç¤ºè©\")\n",
        "                    prompt_for_image = None\n",
        "\n",
        "            except Exception as e:\n",
        "                # Gemini å¯èƒ½é‡åˆ° 429 / 503 / quota å•é¡Œ\n",
        "                gemini_error = f\"{type(e).__name__}: {e}\"\n",
        "                print(\"âš ï¸ Gemini æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œå°‡æ”¹ç”¨åŸºæœ¬æç¤ºè©\")\n",
        "                print(str(e))\n",
        "                prompt_for_image = None\n",
        "\n",
        "        # ============================================================\n",
        "        # C-2. è‹¥ã€Œæœªä½¿ç”¨ Geminiã€æˆ–ã€ŒGemini å¤±æ•—ã€\n",
        "        #     â†’ ä½¿ç”¨ã€åŸºæœ¬æç¤ºè©ã€‘ä¸¦æä¾›çµ¦ä½¿ç”¨è€…æŸ¥çœ‹\n",
        "        # ============================================================\n",
        "        if not prompt_for_image:\n",
        "            # âœ… ç”Ÿåœ–ç”¨ï¼šä¸è¦åŠ  [BASIC PROMPT]ï¼Œé¿å…è¢«æ¨¡å‹ç•¶æˆè¦ç•«å‡ºä¾†çš„æ–‡å­—\n",
        "            prompt_for_image = (\n",
        "                \"Cute 3D Pixar style sticker, chibi character, \"\n",
        "                f\"clear facial expression showing {detected_emotion}, \"\n",
        "                \"simple and clean composition, \"\n",
        "                \"white background, high quality, vector style, die-cut border\"\n",
        "            )\n",
        "\n",
        "            # âœ… UI é¡¯ç¤ºç”¨ï¼šå¯ä»¥åŠ æ¨™ç±¤ï¼Œè®“ä½¿ç”¨è€…çŸ¥é“é€™æ˜¯ basic ç‰ˆæœ¬\n",
        "            if gemini_error:\n",
        "                prompt_for_ui = f\"[GEMINI ERROR] {gemini_error}\\n[BASIC PROMPT] {prompt_for_image}\"\n",
        "            else:\n",
        "                prompt_for_ui = \"[BASIC PROMPT] \" + prompt_for_image\n",
        "\n",
        "            print(\"âœ… ä½¿ç”¨åŸºæœ¬æç¤ºè©ï¼ˆæœªä½¿ç”¨ Gemini æˆ– Gemini ä¸å¯ç”¨ï¼‰\")\n",
        "\n",
        "        # ============================================================\n",
        "        # æ­¥é©Ÿ D: è‡ªå‹•ç”Ÿåœ–\n",
        "        # ============================================================\n",
        "        image_path = generate_image_from_pollinations(prompt_for_image)\n",
        "\n",
        "        # âœ… ç”Ÿåœ–æˆåŠŸæ‰è²¼å­—ï¼ˆåªè²¼ä¸€æ¬¡ï¼‰\n",
        "        if image_path:\n",
        "            image_path = add_speech_text_to_sticker_colab(\n",
        "                image_path=image_path,\n",
        "                speech_text=transcribed_text\n",
        "            )\n",
        "\n",
        "        # ============================================================\n",
        "        # æ­¥é©Ÿ E: å›å‚³çµæœçµ¦ UI\n",
        "        # ============================================================\n",
        "        # UI ç¬¬2æ¬„å»ºè­°é¡¯ç¤ºã€Œå¤šç¶­åº¦æƒ…ç·’çµ„åˆæè¿°ã€æœƒæ›´æœ‰è³‡è¨Šé‡\n",
        "        if image_path:\n",
        "            return transcribed_text, emotion_combo_desc, prompt_for_ui, image_path\n",
        "        else:\n",
        "            return transcribed_text, emotion_combo_desc, prompt_for_ui, None\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"âŒ æµç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}\"\n",
        "        print(error_msg)\n",
        "        return error_msg, \"éŒ¯èª¤\", \"éŒ¯èª¤\", None\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xW1Aog2HIuUg"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 5. ä»‹é¢è¨­è¨ˆå€ (Gradio)\n",
        "# =============================================================================\n",
        "theme = gr.themes.Soft()\n",
        "\n",
        "with gr.Blocks(theme=theme, title=\"AI èªéŸ³è²¼åœ–ç”¢ç”Ÿå™¨ (New GenAI SDK)\") as demo:\n",
        "\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # ğŸ™ï¸ AI èªéŸ³æƒ…ç·’è²¼åœ–ç”¢ç”Ÿå™¨ (å®˜æ–¹æœ€æ–° SDK ç‰ˆ)\n",
        "        ### ä½¿ç”¨ Google æœ€æ–° GenAI SDK + è‡ªå‹•ç”Ÿåœ–\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        api_key_input = gr.Textbox(\n",
        "            label=\"ğŸ”‘ è«‹è¼¸å…¥ Gemini API Key\",\n",
        "            type=\"password\",\n",
        "            placeholder=\"è²¼ä¸Šä½ çš„ API Key...\",\n",
        "        )\n",
        "\n",
        "    with gr.Row():\n",
        "        # å·¦é‚Šï¼šæ“ä½œå€\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### 1. è¼¸å…¥èªéŸ³ ğŸ¤\")\n",
        "            audio_input = gr.Audio(sources=[\"microphone\", \"upload\"], type=\"filepath\")\n",
        "\n",
        "            # âœ… æ–°å¢ï¼šæ˜¯å¦ä½¿ç”¨ Gemini å„ªåŒ–æç¤ºè©\n",
        "            use_gemini_checkbox = gr.Checkbox(\n",
        "                label=\"ğŸ¤– ä½¿ç”¨ Gemini å„ªåŒ–æç¤ºè©ï¼ˆè‹¥ä¸å¯ç”¨å°‡è‡ªå‹•é€€å›åŸºæœ¬ç‰ˆæœ¬ï¼‰\",\n",
        "                value=True\n",
        "            )\n",
        "\n",
        "            btn_generate = gr.Button(\"âœ¨ é–‹å§‹ç”Ÿæˆ (æ–‡å­—+åœ–ç‰‡)\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "            gr.Markdown(\"### 2. åˆ†æçµæœ ğŸ“Š\")\n",
        "            text_output = gr.Textbox(label=\"èªéŸ³è½‰æ–‡å­—\", interactive=False)\n",
        "            emotion_output = gr.Textbox(label=\"åµæ¸¬æƒ…ç·’\", interactive=False)\n",
        "            prompt_output = gr.Textbox(label=\"ç”Ÿæˆçš„æç¤ºè©\", interactive=False, lines=2)\n",
        "\n",
        "        # å³é‚Šï¼šåœ–ç‰‡å±•ç¤ºå€\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### 3. ç”Ÿæˆçš„è²¼åœ– ğŸ–¼ï¸\")\n",
        "            image_output = gr.Image(\n",
        "                label=\"AI ç”Ÿæˆçµæœ\",\n",
        "                type=\"filepath\",\n",
        "                height=512\n",
        "            )\n",
        "\n",
        "\n",
        "    # ç¶å®šåŠŸèƒ½\n",
        "    btn_generate.click(\n",
        "      fn=process_pipeline,\n",
        "      inputs=[api_key_input, audio_input, use_gemini_checkbox],\n",
        "      outputs=[text_output, emotion_output, prompt_output, image_output]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6sksNPYHJrnH",
        "outputId": "37d2fffc-4e7c-4c93-ae61-fdeaa02eb90a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ ä»‹é¢å•Ÿå‹•ä¸­ï¼è«‹é»æ“Šä¸‹æ–¹é€£çµ...\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://39e16772dea5df4566.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://39e16772dea5df4566.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Gemini æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œå°‡æ”¹ç”¨åŸºæœ¬æç¤ºè©\n",
            "503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
            "âœ… ä½¿ç”¨åŸºæœ¬æç¤ºè©ï¼ˆæœªä½¿ç”¨ Gemini æˆ– Gemini ä¸å¯ç”¨ï¼‰\n",
            "æ­£åœ¨è«‹æ±‚ç”Ÿåœ–... Prompt: Cute 3D Pixar style sticker, c...\n",
            "âš ï¸ Gemini æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œå°‡æ”¹ç”¨åŸºæœ¬æç¤ºè©\n",
            "503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
            "âœ… ä½¿ç”¨åŸºæœ¬æç¤ºè©ï¼ˆæœªä½¿ç”¨ Gemini æˆ– Gemini ä¸å¯ç”¨ï¼‰\n",
            "æ­£åœ¨è«‹æ±‚ç”Ÿåœ–... Prompt: Cute 3D Pixar style sticker, c...\n",
            "âœ… ä½¿ç”¨ Gemini æˆåŠŸç”¢ç”Ÿæç¤ºè©\n",
            "æ­£åœ¨è«‹æ±‚ç”Ÿåœ–... Prompt: A cute 3D Pixar style chibi ch...\n",
            "âš ï¸ Gemini æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œå°‡æ”¹ç”¨åŸºæœ¬æç¤ºè©\n",
            "503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
            "âœ… ä½¿ç”¨åŸºæœ¬æç¤ºè©ï¼ˆæœªä½¿ç”¨ Gemini æˆ– Gemini ä¸å¯ç”¨ï¼‰\n",
            "æ­£åœ¨è«‹æ±‚ç”Ÿåœ–... Prompt: Cute 3D Pixar style sticker, c...\n",
            "âœ… ä½¿ç”¨ Gemini æˆåŠŸç”¢ç”Ÿæç¤ºè©\n",
            "æ­£åœ¨è«‹æ±‚ç”Ÿåœ–... Prompt: Cute 3D Pixar style sticker of...\n",
            "âš ï¸ Gemini æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œå°‡æ”¹ç”¨åŸºæœ¬æç¤ºè©\n",
            "503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
            "âœ… ä½¿ç”¨åŸºæœ¬æç¤ºè©ï¼ˆæœªä½¿ç”¨ Gemini æˆ– Gemini ä¸å¯ç”¨ï¼‰\n",
            "æ­£åœ¨è«‹æ±‚ç”Ÿåœ–... Prompt: Cute 3D Pixar style sticker, c...\n",
            "âš ï¸ Gemini æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œå°‡æ”¹ç”¨åŸºæœ¬æç¤ºè©\n",
            "503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
            "âœ… ä½¿ç”¨åŸºæœ¬æç¤ºè©ï¼ˆæœªä½¿ç”¨ Gemini æˆ– Gemini ä¸å¯ç”¨ï¼‰\n",
            "æ­£åœ¨è«‹æ±‚ç”Ÿåœ–... Prompt: Cute 3D Pixar style sticker, c...\n",
            "âœ… ä½¿ç”¨ Gemini æˆåŠŸç”¢ç”Ÿæç¤ºè©\n",
            "æ­£åœ¨è«‹æ±‚ç”Ÿåœ–... Prompt: A cute 3D Pixar style chibi ch...\n",
            "âš ï¸ Gemini æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œå°‡æ”¹ç”¨åŸºæœ¬æç¤ºè©\n",
            "503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
            "âœ… ä½¿ç”¨åŸºæœ¬æç¤ºè©ï¼ˆæœªä½¿ç”¨ Gemini æˆ– Gemini ä¸å¯ç”¨ï¼‰\n",
            "æ­£åœ¨è«‹æ±‚ç”Ÿåœ–... Prompt: Cute 3D Pixar style sticker, c...\n",
            "âš ï¸ Gemini æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œå°‡æ”¹ç”¨åŸºæœ¬æç¤ºè©\n",
            "503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
            "âœ… ä½¿ç”¨åŸºæœ¬æç¤ºè©ï¼ˆæœªä½¿ç”¨ Gemini æˆ– Gemini ä¸å¯ç”¨ï¼‰\n",
            "æ­£åœ¨è«‹æ±‚ç”Ÿåœ–... Prompt: Cute 3D Pixar style sticker, c...\n",
            "âš ï¸ Gemini æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œå°‡æ”¹ç”¨åŸºæœ¬æç¤ºè©\n",
            "503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
            "âœ… ä½¿ç”¨åŸºæœ¬æç¤ºè©ï¼ˆæœªä½¿ç”¨ Gemini æˆ– Gemini ä¸å¯ç”¨ï¼‰\n",
            "æ­£åœ¨è«‹æ±‚ç”Ÿåœ–... Prompt: Cute 3D Pixar style sticker, c...\n",
            "âš ï¸ Gemini æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œå°‡æ”¹ç”¨åŸºæœ¬æç¤ºè©\n",
            "503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
            "âœ… ä½¿ç”¨åŸºæœ¬æç¤ºè©ï¼ˆæœªä½¿ç”¨ Gemini æˆ– Gemini ä¸å¯ç”¨ï¼‰\n",
            "æ­£åœ¨è«‹æ±‚ç”Ÿåœ–... Prompt: Cute 3D Pixar style sticker, c...\n",
            "ç”Ÿåœ–å¤±æ•—ï¼Œç‹€æ…‹ç¢¼: 502\n",
            "âš ï¸ Gemini æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œå°‡æ”¹ç”¨åŸºæœ¬æç¤ºè©\n",
            "503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
            "âœ… ä½¿ç”¨åŸºæœ¬æç¤ºè©ï¼ˆæœªä½¿ç”¨ Gemini æˆ– Gemini ä¸å¯ç”¨ï¼‰\n",
            "æ­£åœ¨è«‹æ±‚ç”Ÿåœ–... Prompt: Cute 3D Pixar style sticker, c...\n",
            "âš ï¸ Gemini æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œå°‡æ”¹ç”¨åŸºæœ¬æç¤ºè©\n",
            "503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
            "âœ… ä½¿ç”¨åŸºæœ¬æç¤ºè©ï¼ˆæœªä½¿ç”¨ Gemini æˆ– Gemini ä¸å¯ç”¨ï¼‰\n",
            "æ­£åœ¨è«‹æ±‚ç”Ÿåœ–... Prompt: Cute 3D Pixar style sticker, c...\n",
            "âš ï¸ Gemini æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œå°‡æ”¹ç”¨åŸºæœ¬æç¤ºè©\n",
            "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 44.397706438s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '44s'}]}}\n",
            "âœ… ä½¿ç”¨åŸºæœ¬æç¤ºè©ï¼ˆæœªä½¿ç”¨ Gemini æˆ– Gemini ä¸å¯ç”¨ï¼‰\n",
            "æ­£åœ¨è«‹æ±‚ç”Ÿåœ–... Prompt: Cute 3D Pixar style sticker, c...\n",
            "âš ï¸ Gemini æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œå°‡æ”¹ç”¨åŸºæœ¬æç¤ºè©\n",
            "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 21.453633578s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '21s'}]}}\n",
            "âœ… ä½¿ç”¨åŸºæœ¬æç¤ºè©ï¼ˆæœªä½¿ç”¨ Gemini æˆ– Gemini ä¸å¯ç”¨ï¼‰\n",
            "æ­£åœ¨è«‹æ±‚ç”Ÿåœ–... Prompt: Cute 3D Pixar style sticker, c...\n",
            "âš ï¸ Gemini æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œå°‡æ”¹ç”¨åŸºæœ¬æç¤ºè©\n",
            "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 15.48761041s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '15s'}]}}\n",
            "âœ… ä½¿ç”¨åŸºæœ¬æç¤ºè©ï¼ˆæœªä½¿ç”¨ Gemini æˆ– Gemini ä¸å¯ç”¨ï¼‰\n",
            "æ­£åœ¨è«‹æ±‚ç”Ÿåœ–... Prompt: Cute 3D Pixar style sticker, c...\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://39e16772dea5df4566.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# 6. å•Ÿå‹•\n",
        "# =============================================================================\n",
        "print(\"ğŸš€ ä»‹é¢å•Ÿå‹•ä¸­ï¼è«‹é»æ“Šä¸‹æ–¹é€£çµ...\")\n",
        "demo.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}